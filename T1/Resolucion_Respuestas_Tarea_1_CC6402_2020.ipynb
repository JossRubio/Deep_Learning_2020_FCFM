{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resolucion_Respuestas_Tarea_1_CC6402_2020",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCszeuRk0NuH"
      },
      "source": [
        "# Tarea 1: Activaciones y pasada hacia adelante en una red neuronal <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: José Rubio\n",
        "Fecha de entrega: 2 de octubre de *2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQB7jV7LMEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "d18da5d5-4f11-47ca-ab1b-ee9cfdd634bb"
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente\n",
        "# !pip install -q ipdb\n",
        "# import ipdb\n",
        "\n",
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cc6204 from git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cc6204) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OevYJkMdgW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2815ca81-f78b-467b-fe52-d44731154b1e"
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "\n",
        "corrector = AutoCorrect(host='cc6204.dcc.uchile.cl', port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "\n",
        "token = ']ye/Ox;nsz'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connection stablished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq9u0IfT0VRp"
      },
      "source": [
        "# Parte 1: Funciones de activación y función de salida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMw80P8o0qrJ"
      },
      "source": [
        "## 1a) Funciones de activación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhcNbNT0YNr"
      },
      "source": [
        "def sig(T):\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * T))\n",
        "\n",
        "def tanh(T):\n",
        "  E = torch.exp(T)\n",
        "  e = torch.exp(-1 * T)\n",
        "  return (E - e) * torch.reciprocal(E + e)\n",
        "\n",
        "# Tu código acá\n",
        "def relu(T):\n",
        "  T = torch.tensor(T)\n",
        "  return (T + torch.abs(T))/(2)\n",
        "\n",
        "def swish(T, beta):\n",
        "  T = torch.tensor(T)\n",
        "  return T*sig(beta*T)\n",
        "\n",
        "def celu(T, alpha):\n",
        "  T = torch.tensor(T)\n",
        "  only_negative = (T - torch.abs(T))/(2)\n",
        "  return (T + torch.abs(T))/(2) + (alpha*(torch.exp(only_negative/alpha)-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0SmO2x7M1pn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "79b33aef-5942-4cc0-af6a-df2f18c9e6e7"
      },
      "source": [
        "# Tests del API del curso\n",
        "test_relu = corrector.get_test_data(homework=1, question=\"1a\", test=1, token=token)\n",
        "test_swish, swish_par = corrector.get_test_data(homework=1, question=\"1a\", test=2, token=token)\n",
        "test_celu, celu_par = corrector.get_test_data(homework=1, question=\"1a\", test=3, token=token)\n",
        "\n",
        "# probablemente quieras convertr los variables test_* a un tensor, ya que por defecto son listas\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=1, token=token, answer=relu(test_relu))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=2, token=token, answer=swish(test_swish, swish_par))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=3, token=token, answer=celu(test_celu, celu_par))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n",
            "Correct Test!\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_0dTh7l1bas"
      },
      "source": [
        "## 1b) Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjIyp2nL1le5"
      },
      "source": [
        "###Demostración de invariabilidad del resultado de *softmax* al restarle el mismo elemento a todas las variables de un arreglo.\n",
        "\n",
        "Anotando la definición de la función, entonces se debe demostrar la siguiente igualdad:\n",
        "\n",
        "$\\frac{e^{x_{i}}}{\\sum_{j=1}^{N}e^{x_{j}}} = \\frac{e^{x_{i}-c}}{\\sum_{j=1}^{N}e^{x_{j}-c}}$\n",
        "\n",
        "Desarrollando el lado derecho, se tiene que por propiedad de las exponenciales, la suma de exponentes equivale al producto de potencias de la misma base. Entonces:\n",
        "\n",
        "$\\frac{e^{x_{i}-c}}{\\sum_{j=1}^{N}e^{x_{j}-c}} = \\frac{e^{-c}e^{x_{i}}}{\\sum_{j=1}^{N}e^{-c}e^{x_{j}}}$\n",
        "\n",
        "En el denominador se tiene un producto entre una constante y la exponencial de la variable, por lo que por propiedad de la sumatoria se puede sacar de esta. Por ende:\n",
        "\n",
        "$\\frac{e^{-c}e^{x_{i}}}{\\sum_{j=1}^{N}e^{-c}e^{x_{j}}} = \\frac{\\not{e^{-c}}e^{x_{i}}}{\\not{e^{-c}}\\sum_{j=1}^{N}e^{x_{j}}} = \\frac{e^{x_{i}}}{\\sum_{j=1}^{N}e^{x_{j}}}$\n",
        "\n",
        "Con lo que el resultado de la función softmax no varia si se quita el mismo elemento a todo el arreglo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDg2sU7D1dIY"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "def softmax(T, dim, estable=True):\n",
        "  T = torch.tensor(T, dtype=torch.float32)\n",
        "  if estable:\n",
        "    T_max = torch.max(T, dim=dim, keepdim=True)\n",
        "    T = torch.exp(T-T_max[0])\n",
        "    T_sum = torch.sum(T, dim=dim, keepdim=True, dtype=torch.float32)\n",
        "    return (T)/(T_sum)\n",
        "  else:\n",
        "    T = torch.exp(T)\n",
        "    T_sum = torch.sum(T, dim, keepdim=True, dtype=torch.float32)\n",
        "    return (T)/(T_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJhjuGZXgkM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0f07e04-ec13-4434-b810-01831c4bea84"
      },
      "source": [
        "# Tests del API del curso\n",
        "test_softmax, _dim = corrector.get_test_data(homework=1, question=\"1b\", test=1, token=token)\n",
        "corrector.sumbit(homework=1, question=\"1b\", test=1, token=token, answer=softmax(test_softmax, dim=_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662XLsDA9XXI"
      },
      "source": [
        "# Parte 2: Red neuronal y pasada hacia adelante (forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUm9ZbX9bRA"
      },
      "source": [
        "## 2a) Clase para red neuronal, 2b) Iterando por parametros, 2d) Pasada hacia adelante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_jeuYbv9WhK"
      },
      "source": [
        "# Tu código debiera continuar así \n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C, bias, W, B, U, C_pre_trained, device):\n",
        "    super(FFNN, self).__init__()\n",
        "    self.F = torch.nn.Parameter(torch.rand(F,dtype=torch.float32))\n",
        "    self.l_h = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(i,dtype=torch.float32)) for i in l_h])\n",
        "    self.bias = torch.nn.ParameterList([torch.nn.Parameter(torch.zeros(k,dtype=torch.float32)) for k in l_h])\n",
        "    self.l_a = l_a\n",
        "    self.C = torch.nn.Parameter(torch.rand(C,dtype=torch.float32))\n",
        "    self.W = torch.nn.ParameterList([torch.nn.Parameter(j) for j in W])\n",
        "    self.B = torch.nn.ParameterList([torch.nn.Parameter(l) for l in B])\n",
        "    self.U = torch.nn.Parameter(U)\n",
        "    self.C_pre_trained = torch.nn.Parameter(C_pre_trained)\n",
        "    self.device = device\n",
        "  \n",
        "  def resumen(self):\n",
        "    # Usa self.parameters() o self.named_parameters().\n",
        "    return self.parameters()\n",
        "  \n",
        "  def forward_random_init(self, x):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # El valor de retorno debiera ser y = softmax(capa_de_salida).\n",
        "    functions = self.l_a\n",
        "    hiddens = self.l_h\n",
        "    x_size = x.size()\n",
        "    if len(x_size) <= 2: # En caso de se estuviese evaluando con un conjunto de muestras.\n",
        "      B, features = x_size\n",
        "      h = x\n",
        "    elif len(x_size) == 3:\n",
        "      B, features = x_size[0], x_size[1]*x_size[2]\n",
        "      h = torch.reshape(x, (B,features))\n",
        "    for hidden, activation in enumerate(functions):\n",
        "      # Extendiendo las capas para redimensionar y que las multiplicaciones matriciales queden bien definidas.\n",
        "      w = hiddens[hidden]\n",
        "      h_prev_size, w_size = h.size()[1], w.size()[0]\n",
        "      w = w.expand(h_prev_size, w_size)\n",
        "      h = activation(h @ w + self.bias[hidden])\n",
        "    C = self.C\n",
        "    h_size, C_size = h.size()[1], C.size()[0]\n",
        "    U = C.expand(h_size, C_size)\n",
        "    # soft = torch.nn.Softmax(dim=1)\n",
        "    # y_pred = soft(h @ U + C)\n",
        "    y_pred = softmax(h @ U + C, dim=1)\n",
        "    return y_pred\n",
        "  \n",
        "  def forward(self, x, predict=False):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # El valor de retorno debiera ser y = softmax(capa_de_salida).\n",
        "    functions = self.l_a\n",
        "    hiddens = self.W\n",
        "    x_size = x.size()\n",
        "    if len(x_size) <= 2: # En caso de se estuviese evaluando con un conjunto de muestras.\n",
        "      B, features = x_size\n",
        "      h = x\n",
        "    elif len(x_size) == 3:\n",
        "      B, features = x_size[0], x_size[1]*x_size[2]\n",
        "      h = torch.reshape(x, (B, features))\n",
        "    elif len(x_size) == 4:\n",
        "      B, features = x_size[0], x_size[1]*x_size[2]*x_size[3]\n",
        "      h = torch.reshape(x, (B, features))\n",
        "    for hidden, activation in enumerate(functions):\n",
        "      # Extendiendo las capas para redimensionar y que las multiplicaciones matriciales queden bien definidas.\n",
        "      w = hiddens[hidden]\n",
        "      if self.device == 'cpu':\n",
        "        h = h.cpu()\n",
        "        w = w.cpu()\n",
        "      elif self.device == 'cuda':\n",
        "        h = h.cuda()\n",
        "        w = w.cuda()\n",
        "      h = activation(h @ w + self.B[hidden])\n",
        "    C = self.C_pre_trained\n",
        "    U = self.U\n",
        "    # soft = torch.nn.Softmax(dim=1)\n",
        "    # y_pred = soft(h @ U + C)\n",
        "    y_pred = softmax(h @ U + C, dim=1)\n",
        "    if predict:\n",
        "      y_pred = torch.reshape(torch.argmax(y_pred, dim=1),(B,))\n",
        "      # y_pred = arg_pred.numpy()\n",
        "      return y_pred\n",
        "    else:\n",
        "      return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgf5Xx-34Pa1"
      },
      "source": [
        "## 2c) Moviendo los parámetros entre dispositivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zppplXd4QXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "af0c1436-a2a5-492e-c0b7-9985b26a5cf0"
      },
      "source": [
        "# Tu código acá\n",
        "# Se inventaron estos vectores solamente para analizar en donde estan siendo asignados los vectores al momento de inicializar la red.\n",
        "W1 = torch.rand([4,5])\n",
        "W2 = torch.rand([4,5])\n",
        "b1 = torch.rand([4,5])\n",
        "b2 = torch.rand([4,5])\n",
        "U = torch.rand([4,5])\n",
        "C = torch.rand([4,5])\n",
        "FNN_test = FFNN(F=5, l_h=[32,16], l_a=[relu,relu], C=10, bias=0, W=[W1,W2], B=[b1,b2], U=U, C_pre_trained=C, device='cuda')\n",
        "FNN_test.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (l_h): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 0)]\n",
              "  )\n",
              "  (bias): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 16 (GPU 0)]\n",
              "  )\n",
              "  (W): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 4x5 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 4x5 (GPU 0)]\n",
              "  )\n",
              "  (B): ParameterList(\n",
              "      (0): Parameter containing: [torch.cuda.FloatTensor of size 4x5 (GPU 0)]\n",
              "      (1): Parameter containing: [torch.cuda.FloatTensor of size 4x5 (GPU 0)]\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTnKxznL6Ep"
      },
      "source": [
        "# Parte 3: Probando tu red con parámetros pre-entrenados para MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBcElJ7BPcQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af01f348-236f-475b-ae90-0271ae1e277b"
      },
      "source": [
        "# Importamos MNIST desde torchvision.\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# Importamos una función para convertir imágenes en tensores.\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Importamos funcionalidades útiles para mirar los datos.\n",
        "from matplotlib.pyplot import subplots\n",
        "from random import randint\n",
        "\n",
        "# Descarga y almacena el conjunto de prueba de MNIST.\n",
        "dataset = MNIST('mnist', train=False, transform=ToTensor(), download=True)\n",
        "print('Cantidad total de datos:',len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad total de datos: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJy5cgY9D_ds",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0ea94bcd-6d1e-4024-dfc4-ac8b73d841e6"
      },
      "source": [
        "T, l = dataset[0]\n",
        "\n",
        "print('Tensor')\n",
        "print('tipo:', T.type())\n",
        "print('dimensiones:', T.size())\n",
        "print()\n",
        "print('Entero')\n",
        "print('valor:', l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor\n",
            "tipo: torch.FloatTensor\n",
            "dimensiones: torch.Size([1, 28, 28])\n",
            "\n",
            "Entero\n",
            "valor: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6s-z1DNL-J0"
      },
      "source": [
        "## 3b) Cargando los parámetros pre-entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLeq3y8FE3SU"
      },
      "source": [
        "# Tu código acá\n",
        "from numpy import loadtxt\n",
        "W1 = torch.from_numpy(loadtxt('W1.txt')).float()\n",
        "W2 = torch.from_numpy(loadtxt('W2.txt')).float()\n",
        "U = torch.from_numpy(loadtxt('U.txt')).float()\n",
        "b1 = torch.from_numpy(loadtxt('b1.txt')).float()\n",
        "b2 = torch.from_numpy(loadtxt('b2.txt')).float()\n",
        "C = torch.from_numpy(loadtxt('c.txt')).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWRa68ZFMIyr"
      },
      "source": [
        "## 3c) Calcula la predicción de un ejemplo al azar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SaIzRoMMoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "37219556-30fe-4c00-e69f-d02ffee97e82"
      },
      "source": [
        "# Tu código acá\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index_example = random.randint(0, len(dataset))\n",
        "T_example, l_example = dataset[index_example]\n",
        "\n",
        "# Muestra de un ejemplo al azar\n",
        "fig, axs = subplots(nrows=1, figsize=(2,1*3))\n",
        "img = T_example.view(28,28).numpy()\n",
        "plt.title('clase: ' + str(l_example))\n",
        "plt.imshow(img)\n",
        "\n",
        "FNN_test = FFNN(F=5, l_h=[32,16], l_a=[relu,relu], C=10, bias=0, W=[W1,W2], B=[b1,b2], U=U, C_pre_trained=C, device='cpu')\n",
        "prediction = FNN_test.forward(T_example, predict=True)\n",
        "\n",
        "print('Clase real: ' + str(l_example))\n",
        "print('Clase predicha: ' +str(prediction.numpy()[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clase real: 2\n",
            "Clase predicha: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1cZFU8rMNr1"
      },
      "source": [
        "## 3d) Pasando todos los ejemplos por la red con un `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL49_0ZAMRd_"
      },
      "source": [
        "# Acá tu código\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=100)\n",
        "\n",
        "def calcula_acierto(red, dataset, batch_size=100, device='cuda'):\n",
        "  network = red\n",
        "  len_data = len(dataset)\n",
        "  dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
        "  accuracy = []\n",
        "  if device == 'cuda':\n",
        "    network.cuda()\n",
        "  elif device == 'cpu':\n",
        "    network.cpu()\n",
        "  for x, y in dataloader:\n",
        "    predictions = network.forward(x, predict=True)\n",
        "    failed_pred = y - predictions\n",
        "    accuracy_batch = torch.reshape((failed_pred == 0).sum(dim=0), (1,)).numpy()[0]\n",
        "    accuracy.append(accuracy_batch)\n",
        "  return sum(accuracy)/len_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTHbWEum_pHX"
      },
      "source": [
        "###Prueba CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4WgDK6IzyWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "e75ba3aa-f91a-42ee-edc4-2e6f784978f0"
      },
      "source": [
        "import time\n",
        "\n",
        "time_i = time.time()\n",
        "\n",
        "Network = FFNN(F=784, l_h =[32, 16], l_a=[relu, relu],C=10, bias=0, W=[W1,W2], B=[b1,b2], U=U, C_pre_trained=C, device='cpu')\n",
        "Accuracy = calcula_acierto(red=Network, dataset=dataset, batch_size=10000, device='cpu')\n",
        "\n",
        "time_f = time.time()\n",
        "Time = time_f - time_i\n",
        "print('Accuracy del sistema: ' + str(Accuracy))\n",
        "print('Tiempo requerido: ' + str(Time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy del sistema: 0.9612\n",
            "Tiempo requerido: 0.6781997680664062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c05Vx0hB_si0"
      },
      "source": [
        "###Prueba GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIMIBZYb_wHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "daa58501-1849-458a-c8fc-0b5b2f638d1a"
      },
      "source": [
        "import time\n",
        "\n",
        "time_i = time.time()\n",
        "\n",
        "Network = FFNN(F=784, l_h =[32, 16], l_a=[relu, relu],C=10, bias=0, W=[W1,W2], B=[b1,b2], U=U, C_pre_trained=C, device='cuda')\n",
        "Accuracy = calcula_acierto(red=Network, dataset=dataset, batch_size=10000, device='cuda')\n",
        "\n",
        "time_f = time.time()\n",
        "Time = time_f - time_i\n",
        "print('Accuracy del sistema: ' + str(Accuracy))\n",
        "print('Tiempo requerido: ' + str(Time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy del sistema: 0.9612\n",
            "Tiempo requerido: 0.6342356204986572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldjmy_-ZCZ4q"
      },
      "source": [
        "Al aumentar el tamaño del batch, entonces el sistema realiza una menor cantidad de iteraciones, por lo que el proceso se acelera. Ademas al variar a la GPU tambien se reduce la cantidad de tiempo requerido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXqo4FpX2Id"
      },
      "source": [
        "### Corrección red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMcid2LRXzrg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "091f3111-29d8-4a56-cc5b-a79201a2039f"
      },
      "source": [
        "# Tests del API del curso\n",
        "from torch.utils.data import Subset\n",
        "indices = corrector.get_test_data(homework=1, question=\"network\", test=1, token=token)\n",
        "test_set = Subset(dataset, indices)\n",
        "\n",
        "# Modelo con los parámetros pre-entrenados para MNIST\n",
        "your_network = FFNN(F=784, l_h =[32, 16], l_a=[relu, relu],C=10, bias=0, W=[W1,W2], B=[b1,b2], U=U, C_pre_trained=C, device='cpu')\n",
        "\n",
        "# Montar el `test_set` en un tensor de (N, 28*28) usando DataLoader\n",
        "X = list(DataLoader(test_set, batch_size=len(test_set)))[0][0].view(-1, 28*28)\n",
        "\n",
        "# Almacenar el resultado en un puro tensor de (N,1)\n",
        "result = torch.argmax(your_network.forward(X), dim=1)\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"network\", test=1, token=token, answer=result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pgWygWCMYTx"
      },
      "source": [
        "## 3e) Opcional: Muestra los casos en donde la red se equivoca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM_eP23XMaTn"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beF870pABHKe"
      },
      "source": [
        "## 3d) Opcional: Crea tus propios ejemplos de dígitos para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOqCJx4LBG1W"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}